{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fc734-3c55-432d-a739-e4ac1fff48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "import nomad.io.base as loader\n",
    "from nomad.filters import _compute_q_stat\n",
    "import nomad.stop_detection.grid_based as sd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530edab8-5aa7-43d3-a72c-73742b68dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_Q_matrix(traj, traj_cols):\n",
    "    '''\n",
    "    generate Q daily matrix\n",
    "    '''\n",
    "    df = traj.copy()\n",
    "    #Compute number of complete users over each window with 1-day timestep\n",
    "    df['date_hour'] = df[traj_cols['datetime']].dt.floor('h')\n",
    "    df['date'] = df[traj_cols['datetime']].dt.date\n",
    "    df_downsampled_1hour = df[[traj_cols['user_id'],'date','date_hour']].drop_duplicates()\n",
    "    df_date_nhours = df_downsampled_1hour.groupby([traj_cols['user_id'],'date']).size().reset_index()\n",
    "    df_date_nhours.rename(columns = {0:'nhours'}, inplace = True)\n",
    "    df_date_nhours['perc_hours'] = df_date_nhours['nhours']/24\n",
    "    Q = df_date_nhours.pivot(index = 'date', \n",
    "                             columns = traj_cols['user_id'], \n",
    "                             values = 'perc_hours').fillna(0)\n",
    "    return Q\n",
    "\n",
    "\n",
    "def _compute_mean_q(Q, date, SW_width_days):\n",
    "    '''\n",
    "    compute average q over a single sliding window iteration \n",
    "    that is for a given day, take the window [day, day + SW_width_days] and compute individual q mean for all users\n",
    "    '''\n",
    "    #select index corresponding to the date\n",
    "    i = np.argwhere(Q.index==date).ravel()[0]\n",
    "    #compute the q mean over the specific sliding window iteration\n",
    "    return Q[i:i+SW_width_days].mean(axis=0)\n",
    "\n",
    "def numerical_date_range(start_date: int, end_date: int):\n",
    "    \"\"\"Return every calendar day from start_date to end_date inclusive, each as an int YYYYMMDD.\"\"\"\n",
    "    s = str(start_date)\n",
    "    e = str(end_date)\n",
    "    start_dt = date(int(s[:4]), int(s[4:6]), int(s[6:]))\n",
    "    end_dt   = date(int(e[:4]), int(e[4:6]), int(e[6:]))\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(\"start_date must not be after end_date\")\n",
    "    span = (end_dt - start_dt).days\n",
    "    return [int((start_dt + timedelta(days=i)).strftime(\"%Y%m%d\")) for i in range(span + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891205d-f11e-4f45-90e7-7a73b1e84271",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.table_columns('BASELINE_PINGS_BY_NIGHTS', format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38a761-e21d-4478-9011-e532d4b1ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dates = numerical_date_range(20241126, 20250113)\n",
    "dates = pd.date_range('2024-11-26', '2025-01-13').astype(str).tolist()\n",
    "\n",
    "skipped_dates = [dates[5*i] for i in range(10)]+ [dates[-1]]\n",
    "skipped_dates_num = [num_dates[5*i] for i in range(10)]+ [num_dates[-1]]\n",
    "\n",
    "filter_lists = [[(\"processing_date\", \">=\", skipped_dates_num[j]), (\"event_zoned_datetime\", \">=\", skipped_dates[j]), (\"event_zoned_datetime\", \"<\", skipped_dates[j+1])] for j in range(len(skipped_dates)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236923fe-ae9e-447f-90bc-d810a5f3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_matrices = []\n",
    "for fltrs in filter_lists:\n",
    "    df = loader.from_file('BASELINE_PINGS_BY_NIGHTS',\n",
    "                          format='parquet',\n",
    "                          latitude='lat',\n",
    "                          longitude='lng',\n",
    "                          timestamp='event_timestamp',\n",
    "                          datetime='event_zoned_datetime',\n",
    "                          filters=fltrs)\n",
    "    Q_matrices += [ _generate_Q_matrix(df, traj_cols={'datetime':'event_zoned_datetime', 'user_id':'cuebiq_id'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162078b-d6e5-404a-ba87-e2b90c5b5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = pd.concat(Q_matrices).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a70d7-58fe-46d9-a175-84e4931ce9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 42\n",
    "\n",
    "q_hourly = Q.mean(axis=0)*100\n",
    "q_daily = ((Q>0.0).sum(axis=0)/num_days)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c8322-28e3-462f-8a1a-8ba642a1f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume Q is your DataFrame and q_daily is the Series of mean completeness per user\n",
    "sorted_cols = q_daily.sort_values(ascending=False).index\n",
    "Qs = Q[sorted_cols]\n",
    "binary = Qs.gt(0).astype(int)\n",
    "cmap = plt.cm.Blues\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 8),\n",
    "    gridspec_kw={'height_ratios': [1, 2.5]},\n",
    "    sharey='row'\n",
    ")\n",
    "\n",
    "# marginal histograms\n",
    "axes[0,0].hist(q_daily, bins=46)\n",
    "axes[0,0].set_xlabel('% days with data')\n",
    "\n",
    "axes[0,1].hist(q_hourly, bins=46)\n",
    "axes[0,1].set_xlabel('% hours with data')\n",
    "\n",
    "for ax, data in zip([axes[0,1], axes[0,0]], (q_hourly, q_daily)):\n",
    "    ax.axvline(np.median(data), linestyle='--', color='red', lw=1)\n",
    "# binary heatmap\n",
    "sns.heatmap(\n",
    "    binary.T,\n",
    "    ax=axes[1,0],\n",
    "    cmap=cmap,\n",
    "    vmin=0, vmax=1,\n",
    "    cbar=False,\n",
    "    xticklabels=False,\n",
    "    yticklabels=False\n",
    ")\n",
    "axes[1,0].set_ylabel('User')\n",
    "\n",
    "# continuous heatmap\n",
    "sns.heatmap(\n",
    "    Qs.T,\n",
    "    ax=axes[1, 1],\n",
    "    cmap=cmap,\n",
    "    vmin=0, vmax=1,\n",
    "    cbar_kws={'label': 'Completeness'},\n",
    "    xticklabels=False,\n",
    "    yticklabels=False\n",
    ")\n",
    "axes[1,1].set_ylabel('')\n",
    "\n",
    "# set date ticks on bottom row\n",
    "dates = pd.to_datetime(Qs.index)\n",
    "tick_locs = np.linspace(0, len(dates) - 1, 6, dtype=int)\n",
    "tick_lbls = dates.strftime('%m-%d')[tick_locs]\n",
    "for ax in [axes[1,0], axes[1,1]]:\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(tick_lbls, rotation=45, ha='right')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bc0cb-51c4-4f09-8bb6-40277a4c6b38",
   "metadata": {},
   "source": [
    "# Home attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37d39c-28b2-4a25-99a3-26170daca6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'cuebiq_id',\n",
    "             'latitude':'lat',\n",
    "             'longitude':'lng',\n",
    "             'timestamp':'event_timestamp',\n",
    "             'datetime':'event_zoned_datetime'}\n",
    "users = loader.sample_users('BASELINE_PINGS_BY_NIGHTS', format='parquet', size=1.0, traj_cols=traj_cols)\n",
    "user_chunks = np.array_split(users.values, 10)\n",
    "user_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d43e1-d58e-4e2a-988b-dd358a91a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stops = []\n",
    "for user_chunk in user_chunks:\n",
    "    df =loader.sample_from_file(\n",
    "        'BASELINE_PINGS_BY_NIGHTS',\n",
    "        format='parquet',\n",
    "        users=user_chunk,\n",
    "        traj_cols=traj_cols)\n",
    "    stops = df.groupby('cuebiq_id').apply(grid_based_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a9417-3d91-4819-a421-33f526a1a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_based_sd = partial(sd.grid_based_labels, traj_cols=traj_cols, location_id='zipcode_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163387b-5cfb-446b-a05b-6850e9777778",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = df.groupby('cuebiq_id').apply(grid_based_sd).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b2689-3152-415d-b8a9-482bb0c5ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9db04-033e-4774-a116-9427aa6f0826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
